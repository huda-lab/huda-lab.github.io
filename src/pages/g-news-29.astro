---
import "normalize.css/normalize.css";
import "../style/global.scss";

import Header from "../components/Header.astro";
import Footer from "../components/Footer.astro";
---

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width" />
    <meta name="description" content="MirrorBench Leak: Probing Private Data Echo in Large Language Models. Analysis of sensitive data surfacing in AI outputs." />
    <link rel="sitemap" href="/sitemap-index.xml" />
    <link rel="manifest" href="/manifest.json" />
    <link rel="shortcut icon" href="/favicon.ico" />
    <link rel="icon" type="image/x-icon" href="/favicon.ico" />
    <title>MirrorBench Leak: Data Echo Analysis - مختبر هدا</title>
  </head>
  <body>
    <Header />
    <main>
      <article class="news-post">
        <div class="container">
          <header class="post-header">
            <h1 class="post-title">MirrorBench Leak: Probing Private Data Echo in Large Language Models</h1>
            <div class="post-meta">
              <span class="post-date">Experimental Series</span>
              <span class="post-author">By MirrorBench Initiative</span>
            </div>
            <div class="post-tags">
              <span class="tag">AI Safety</span>
              <span class="tag">Privacy</span>
              <span class="tag">Data Leakage</span>
              <span class="tag">Experimental</span>
            </div>
          </header>

          <div class="post-content">
            <section class="summary-box">
              <h2>Overview</h2>
              <p>Researchers with the MirrorBench Initiative have circulated a draft benchmark intended to measure what they describe as <strong>private data echo</strong>: cases where a model surfaces sensitive or personal details without relying on traditional “prompt injection” patterns, but instead through seemingly harmless queries and indirect contextual hints.</p>
            </section>

            <section class="article-section">
              <h2>The Mechanism</h2>
              <p>MirrorBench Leak constructs “decoy contexts” (short narratives, support interactions, HR-style memos) that include non-identifying attributes such as role, location, or coarse date ranges, while intentionally omitting direct identifiers. The model is then prompted for summaries, reformulations, or suggested next actions.</p>
              <p>Model outputs are evaluated with a strict matching pipeline that focuses exclusively on high-specificity strings and then verifies whether they align with a protected reference corpus.</p>
              <p>Metrics are reported over 18,000 prompts, 12 decoy templates, and a mixed reference collection (support, billing, scheduling, and “public record” domains).</p>
            </section>

            <section class="article-section">
              <h2>Why calling it a “Leak” sparks debate</h2>
              <p>The authors contend that the term “leak” is justified because the benchmark highlights outputs that resemble the disclosure of protected identifiers. Skeptics respond that what is observed may be better described as boundary cases of training-data memorization rather than active retrieval from private stores.</p>
              <blockquote class="expert-quote">
                <p>“We are not claiming that models are querying hidden databases. Our point is that the gap between ‘innocent prompt’ and ‘identifier emission’ is narrower than we expected.”</p>
                <cite>— Dr. Inez Vale, MirrorBench Lead</cite>
              </blockquote>
            </section>

            <section class="article-section">
              <h2>What MirrorBench Leak actually captures (and what it leaves out)</h2>
              <p>The latest iteration Focusing on the "identifier emission" is narrower than we expected, specifically in support, billing, scheduling, and “public record” domains.</p>
            </section>

            <section class="article-section">
              <h2>Limitations and open questions</h2>
              <ul>
                <li><strong>Reference set sensitivity:</strong> Findings are tied to how the protected record set is built and curated.</li>
                <li><strong>Template disclosure risk:</strong> Revealing too much about decoy templates may enable gaming or unintended leakage.</li>
                <li><strong>Interpretation gap:</strong> Echo events do not automatically imply live data access; they may reflect memorized patterns.</li>
                <li><strong>Need for independent trials:</strong> External replications with alternative templates are required before using results for model comparisons.</li>
              </ul>
            </section>

            </section>

            <section class="article-section border-top">
              <h2>Related frameworks and background</h2>
              <ol>
                <li><a href="https://www.nist.gov/itl/ai-risk-management-framework">NIST AI Risk Management Framework</a> — a lifecycle view of risk management for deployed AI systems.</li>
                <li><a href="https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf">NIST AI RMF 1.0 (PDF)</a> — guidance language on transparency, accountability, and evaluation practices.</li>
              </ol>
            </section>

             <section class="article-section">
              <div class="call-to-action">
                <h3>Explore the Full Series</h3>
                <p>This report is one of eight experimental briefings on AI coordination, automation, and infrastructure shifts.</p>
                <div class="cta-buttons">
                  <a href="/contents" class="cta-btn primary">Back to Project Map</a>
                  <a href="/g-news-30" class="cta-btn secondary">Next: Agent Deadlock Syndrome</a>
                </div>
              </div>
            </section>
          </div>
        </div>
      </article>
    </main>
    <Footer />

    <style lang="scss">
      body {
        width: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
        min-height: 100vh;
        background: #fdfdfd;
      }

      main {
        width: 100%;
        max-width: 900px;
        padding: 2rem;
      }

      .news-post {
        background: white;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        overflow: hidden;
        border-top: 5px solid #4285f4; /* Blue accent for research */
      }

      .container {
        padding: 2.5rem;
      }

      .post-header {
        margin-bottom: 2.5rem;
        padding-bottom: 1.5rem;
        border-bottom: 1px solid #eee;
      }

      .post-title {
        font-size: 2.2rem;
        font-weight: 800;
        color: #202124;
        margin-bottom: 1rem;
        line-height: 1.2;
      }

      .post-meta {
        display: flex;
        gap: 1.5rem;
        font-size: 0.9rem;
        color: #5f6368;
        margin-bottom: 1rem;
      }
      
      .post-date {
        color: #4285f4;
        font-weight: 700;
      }

      .post-tags {
        display: flex;
        gap: 0.5rem;
        flex-wrap: wrap;
      }

      .tag {
        background: #f1f3f4;
        color: #3c4043;
        padding: 0.2rem 0.6rem;
        border-radius: 4px;
        font-size: 0.75rem;
        font-weight: 600;
        text-transform: uppercase;
      }

      .summary-box {
        background: #e8f0fe;
        border: 1px solid #d2e3fc;
        border-left: 4px solid #4285f4;
        border-radius: 8px;
        padding: 1.5rem;
        margin-bottom: 2.5rem;
      }

      .summary-box h2 {
        margin-bottom: 0.8rem;
        font-size: 1.2rem;
        color: #1967d2;
        font-weight: 800;
      }

      .article-section {
        margin-bottom: 2.5rem;
        
        &.border-top {
          border-top: 1px solid #eee;
          padding-top: 2rem;
        }
      }

      .article-section h2 {
        font-size: 1.5rem;
        font-weight: 700;
        color: #202124;
        margin-bottom: 1rem;
      }
      
      .article-section p {
        line-height: 1.7;
        color: #3c4043;
        margin-bottom: 1rem;
      }

      .expert-quote {
        background: #f8f9fa;
        border-left: 4px solid #4285f4;
        padding: 1.5rem;
        border-radius: 0 8px 8px 0;
        margin: 2rem 0;
      }

      .expert-quote p {
        font-style: italic;
        font-size: 1.1rem;
        color: #3c4043;
        margin-bottom: 0.8rem;
      }

      .expert-quote cite {
        font-size: 0.9rem;
        font-weight: 600;
        color: #5f6368;
        display: block;
      }

      .call-to-action {
        background: #f8f9fa;
        border: 1px solid #dadce0;
        padding: 2rem;
        border-radius: 8px;
        text-align: center;
      }

      .cta-buttons {
        display: flex;
        justify-content: center;
        gap: 1rem;
        margin-top: 1.5rem;
      }

      .cta-btn {
        padding: 0.6rem 1.2rem;
        border-radius: 4px;
        font-weight: 600;
        text-decoration: none;
        font-size: 0.95rem;
        transition: background-color 0.2s;
        border: none;
        cursor: pointer;
        
        &.primary {
          background: #4285f4;
          color: white;
          
          &:hover {
             background: #1967d2;
          }
        }
        
        &.secondary {
           background: white;
           color: #4285f4;
           border: 1px solid #dadce0;
           
           &:hover {
              background: #f1f3f4;
           }
        }
      }

      @media (max-width: 768px) {
        .container {
          padding: 1.5rem;
        }
        .post-title {
          font-size: 1.8rem;
        }
      }
    </style>
  </body>
</html>
